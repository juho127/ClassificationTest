{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CIFAR-10 MLP Î∂ÑÎ•ò Ïã§Ïäµ\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juho127/ClassificationTest/blob/main/cifar10_mlp_tutorial.ipynb)\n",
        "\n",
        "Ïù¥ ÎÖ∏Ìä∏Î∂ÅÏóêÏÑúÎäî CIFAR-10 Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Îã§Ï∏µ ÌçºÏÖâÌä∏Î°†(MLP)ÏúºÎ°ú Ïù¥ÎØ∏ÏßÄ Î∂ÑÎ•òÎ•º ÏàòÌñâÌï©ÎãàÎã§.\n",
        "\n",
        "## üöÄ Google ColabÏóêÏÑú Ïã§ÌñâÌïòÎäî Í≤ΩÏö∞\n",
        "1. **Îü∞ÌÉÄÏûÑ > Îü∞ÌÉÄÏûÑ Ïú†Ìòï Î≥ÄÍ≤Ω > GPU** ÏÑ†ÌÉù (ÌïôÏäµ ÏÜçÎèÑÍ∞Ä Ìõ®Ïî¨ Îπ®ÎùºÏßëÎãàÎã§!)\n",
        "2. ÏÖÄÏùÑ ÏàúÏÑúÎåÄÎ°ú Ïã§Ìñâ (Shift + Enter)\n",
        "\n",
        "## Î™©Ï∞®\n",
        "1. ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏\n",
        "2. Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú Î∞è ÌÉêÏÉâ\n",
        "3. MLP Î™®Îç∏ Ï†ïÏùò\n",
        "4. ÌïôÏäµ Î∞è ÌèâÍ∞Ä\n",
        "5. Í≤∞Í≥º Î∂ÑÏÑù\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. ÌôòÍ≤Ω ÏÑ§Ï†ï (Google Colab Ï†ÑÏö©)\n",
        "\n",
        "**ColabÏóêÏÑú Ïã§ÌñâÌïòÎäî Í≤ΩÏö∞**: ÏïÑÎûò ÏÖÄÏùÑ Ïã§ÌñâÌïòÏÑ∏Ïöî.  \n",
        "**Î°úÏª¨ÏóêÏÑú Ïã§ÌñâÌïòÎäî Í≤ΩÏö∞**: ÏïÑÎûò ÏÖÄÏùÑ Í±¥ÎÑàÎõ∞ÏÑ∏Ïöî.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Colab ÌôòÍ≤Ω ÌôïÏù∏ Î∞è ÏÑ§Ï†ï\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"‚úì Google Colab ÌôòÍ≤ΩÏóêÏÑú Ïã§Ìñâ Ï§ëÏûÖÎãàÎã§.\")\n",
        "    print(\"üìå ÌåÅ: Îü∞ÌÉÄÏûÑ > Îü∞ÌÉÄÏûÑ Ïú†Ìòï Î≥ÄÍ≤Ω > GPUÎ•º ÏÑ†ÌÉùÌïòÎ©¥ Îçî Îπ†Î¶ÖÎãàÎã§!\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"‚úì Î°úÏª¨ ÌôòÍ≤ΩÏóêÏÑú Ïã§Ìñâ Ï§ëÏûÖÎãàÎã§.\")\n",
        "\n",
        "# ColabÏóêÏÑú ÌïÑÏöîÌïú Í≤ΩÏö∞ Ï∂îÍ∞Ä Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò\n",
        "if IN_COLAB:\n",
        "    print(\"\\nÌïÑÏöîÌïú Ìå®ÌÇ§ÏßÄÎ•º ÌôïÏù∏ÌïòÎäî Ï§ë...\")\n",
        "    # ColabÏóêÎäî ÎåÄÎ∂ÄÎ∂Ñ ÏÑ§ÏπòÎêòÏñ¥ ÏûàÏßÄÎßå, ÌôïÏù∏Ï∞® Ïã§Ìñâ\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install -q torch torchvision tqdm matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(f\"PyTorch Î≤ÑÏ†Ñ: {torch.__version__}\")\n",
        "print(f\"CUDA ÏÇ¨Ïö© Í∞ÄÎä•: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Ïù¥Î¶Ñ: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"üéâ GPUÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Îπ†Î•¥Í≤å ÌïôÏäµÌï† Ïàò ÏûàÏäµÎãàÎã§!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú Î∞è ÌÉêÏÉâ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 10  # ÎÖ∏Ìä∏Î∂ÅÏóêÏÑúÎäî ÏßßÍ≤å ÏÑ§Ï†ï (ÏãúÍ∞ÑÏù¥ ÏûàÎã§Î©¥ 20ÏúºÎ°ú ÎäòÎ†§Î≥¥ÏÑ∏Ïöî!)\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# CIFAR-10 ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ\n",
        "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', \n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "print(f\"ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: {DEVICE}\")\n",
        "if DEVICE.type == 'cuda':\n",
        "    print(\"‚úì GPUÎ•º ÏÇ¨Ïö©Ìï©ÎãàÎã§!\")\n",
        "else:\n",
        "    print(\"‚Ñπ CPUÎ•º ÏÇ¨Ïö©Ìï©ÎãàÎã§. (ColabÏùò Í≤ΩÏö∞: Îü∞ÌÉÄÏûÑ > Îü∞ÌÉÄÏûÑ Ïú†Ìòï Î≥ÄÍ≤Ω > GPU)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# CIFAR-10 Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample images\n",
        "def show_images(loader, num_images=10):\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = next(dataiter)\n",
        "    \n",
        "    # Denormalize\n",
        "    images = images / 2 + 0.5\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "    fig.suptitle('CIFAR-10 Sample Images', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    for idx, ax in enumerate(axes.flat):\n",
        "        if idx < num_images:\n",
        "            img = images[idx].numpy().transpose((1, 2, 0))\n",
        "            ax.imshow(img)\n",
        "            ax.set_title(f'{CLASSES[labels[idx]]}')\n",
        "            ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_images(train_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. MLP Î™®Îç∏ Ï†ïÏùò\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"Îã§Ï∏µ ÌçºÏÖâÌä∏Î°† Î™®Îç∏\"\"\"\n",
        "    \n",
        "    def __init__(self, input_size=3072, hidden_size1=512, hidden_size2=256, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        \n",
        "        # Ï≤´ Î≤àÏß∏ ÏùÄÎãâÏ∏µ\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        \n",
        "        # Îëê Î≤àÏß∏ ÏùÄÎãâÏ∏µ\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        \n",
        "        # Ï∂úÎ†•Ï∏µ\n",
        "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Ïù¥ÎØ∏ÏßÄÎ•º 1Ï∞®ÏõêÏúºÎ°ú ÌéºÏπòÍ∏∞ (32x32x3 = 3072)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # Ï≤´ Î≤àÏß∏ ÏùÄÎãâÏ∏µ\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.dropout1(x)\n",
        "        \n",
        "        # Îëê Î≤àÏß∏ ÏùÄÎãâÏ∏µ\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.dropout2(x)\n",
        "        \n",
        "        # Ï∂úÎ†•Ï∏µ\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Î™®Îç∏ ÏÉùÏÑ±\n",
        "model = MLP().to(DEVICE)\n",
        "print(model)\n",
        "\n",
        "# ÌååÎùºÎØ∏ÌÑ∞ Ïàò Í≥ÑÏÇ∞\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\nÏ†ÑÏ≤¥ ÌååÎùºÎØ∏ÌÑ∞ Ïàò: {total_params:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ÌïôÏäµ Î∞è ÌèâÍ∞Ä\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÏÜêÏã§ Ìï®Ïàò Î∞è ÏòµÌã∞ÎßàÏù¥Ï†Ä\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Statistics\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{running_loss/total:.4f}',\n",
        "            'acc': f'{100*correct/total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Evaluate function\n",
        "def evaluate(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    test_loss = test_loss / total\n",
        "    test_acc = 100 * correct / total\n",
        "    return test_loss, test_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "test_losses = []\n",
        "test_accs = []\n",
        "\n",
        "print(\"Starting training!\\n\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Training\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    \n",
        "    # Evaluation\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accs.append(test_acc)\n",
        "    \n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
        "    print(f\"  Test  - Loss: {test_loss:.4f}, Acc: {test_acc:.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "print(\"\\nÌïôÏäµ ÏôÑÎ£å!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Í≤∞Í≥º Î∂ÑÏÑù\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize training history\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "# Loss graph\n",
        "ax1.plot(epochs, train_losses, 'b-', label='Train Loss', linewidth=2)\n",
        "ax1.plot(epochs, test_losses, 'r-', label='Test Loss', linewidth=2)\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.set_title('Training History: Loss', fontsize=14, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy graph\n",
        "ax2.plot(epochs, train_accs, 'b-', label='Train Accuracy', linewidth=2)\n",
        "ax2.plot(epochs, test_accs, 'r-', label='Test Accuracy', linewidth=2)\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax2.set_title('Training History: Accuracy', fontsize=14, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final test accuracy: {test_accs[-1]:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ÌÅ¥ÎûòÏä§Î≥Ñ Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞\n",
        "class_correct = [0] * 10\n",
        "class_total = [0] * 10\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "print(\"Per-class Accuracy:\")\n",
        "for i in range(10):\n",
        "    acc = 100 * class_correct[i] / class_total[i]\n",
        "    print(f'  {CLASSES[i]:10s}: {acc:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize prediction results\n",
        "def visualize_predictions(model, loader, num_images=10):\n",
        "    model.eval()\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = next(dataiter)\n",
        "    images_display = images / 2 + 0.5  # Denormalize\n",
        "    \n",
        "    images = images.to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "    fig.suptitle('Model Prediction Results', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    for idx, ax in enumerate(axes.flat):\n",
        "        if idx < num_images:\n",
        "            img = images_display[idx].numpy().transpose((1, 2, 0))\n",
        "            ax.imshow(img)\n",
        "            \n",
        "            pred_label = CLASSES[predicted[idx]]\n",
        "            true_label = CLASSES[labels[idx]]\n",
        "            color = 'green' if predicted[idx] == labels[idx] else 'red'\n",
        "            \n",
        "            ax.set_title(f'Pred: {pred_label}\\nTrue: {true_label}', color=color, fontsize=10)\n",
        "            ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_predictions(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ïã§Ïäµ Í≥ºÏ†ú\n",
        "\n",
        "Îã§Ïùå ÎÇ¥Ïö©ÏùÑ Ïã§ÌóòÌï¥Î≥¥ÏÑ∏Ïöî:\n",
        "\n",
        "1. **ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï**\n",
        "   - ÌïôÏäµÎ•†ÏùÑ Î≥ÄÍ≤ΩÌï¥Î≥¥ÏÑ∏Ïöî (0.0001, 0.01 Îì±)\n",
        "   - Î∞∞Ïπò ÌÅ¨Í∏∞Î•º Î≥ÄÍ≤ΩÌï¥Î≥¥ÏÑ∏Ïöî (64, 256 Îì±)\n",
        "   - ÏóêÌè¨ÌÅ¨ ÏàòÎ•º ÎäòÎ†§Î≥¥ÏÑ∏Ïöî\n",
        "\n",
        "2. **Î™®Îç∏ Íµ¨Ï°∞ Î≥ÄÍ≤Ω**\n",
        "   - ÏùÄÎãâÏ∏µÏùÑ Ï∂îÍ∞ÄÌï¥Î≥¥ÏÑ∏Ïöî\n",
        "   - ÏùÄÎãâÏ∏µÏùò Îâ¥Îü∞ ÏàòÎ•º Î≥ÄÍ≤ΩÌï¥Î≥¥ÏÑ∏Ïöî\n",
        "   - Dropout ÎπÑÏú®ÏùÑ Î≥ÄÍ≤ΩÌï¥Î≥¥ÏÑ∏Ïöî\n",
        "\n",
        "3. **Í≤∞Í≥º Î∂ÑÏÑù**\n",
        "   - Ïñ¥Îñ§ ÌÅ¥ÎûòÏä§Í∞Ä Î∂ÑÎ•òÌïòÍ∏∞ Ïñ¥Î†§Ïö¥Í∞ÄÏöî?\n",
        "   - Í≥ºÏ†ÅÌï©(Overfitting)Ïù¥ Î∞úÏÉùÌïòÎÇòÏöî?\n",
        "   - MLPÏùò ÌïúÍ≥ÑÏ†êÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî?\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
